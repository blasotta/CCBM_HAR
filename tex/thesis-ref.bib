
@inproceedings{gens_learning_2013,
	title = {Learning the {Structure} of {Sum}-{Product} {Networks}},
	abstract = {Sum-product networks (SPNs) are a new class of deep probabilistic models. SPNs can have unbounded treewidth but inference in them is always tractable. An SPN is either a univariate distribution, a product of SPNs over disjoint variables, or a weighted sum of SPNs over the same variables. We propose the ﬁrst algorithm for learning the structure of SPNs that takes full advantage of their expressiveness. At each step, the algorithm attempts to divide the current variables into approximately independent subsets. If successful, it returns the product of recursive calls on the subsets; otherwise it returns the sum of recursive calls on subsets of similar instances from the current training set. A comprehensive empirical study shows that the learned SPNs are typically comparable to graphical models in likelihood but superior in inference speed and accuracy.},
	language = {en},
	booktitle = {{PMLR}},
	author = {Gens, Robert and Domingos, Pedro},
	year = {2013},
	pages = {873--880},
	file = {Gens and Domingos - Learning the Structure of Sum-Product Networks.pdf:C\:\\Users\\bened\\Zotero\\storage\\YCQW6ZE3\\Gens and Domingos - Learning the Structure of Sum-Product Networks.pdf:application/pdf},
}

@article{kobyzev_normalizing_2021,
	title = {Normalizing {Flows}: {An} {Introduction} and {Review} of {Current} {Methods}},
	volume = {43},
	issn = {1939-3539},
	shorttitle = {Normalizing {Flows}},
	doi = {10.1109/TPAMI.2020.2992934},
	abstract = {Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.},
	number = {11},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Kobyzev, Ivan and Prince, Simon J.D. and Brubaker, Marcus A.},
	month = nov,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Training, Computational modeling, Context modeling, density estimation, Estimation, Generative models, invertible neural networks, Jacobian matrices, Mathematical model, normalizing flows, Random variables, variational inference},
	pages = {3964--3979},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bened\\Zotero\\storage\\VKBTAVUN\\9089305.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\3H2Q3XXV\\Kobyzev et al. - 2021 - Normalizing Flows An Introduction and Review of C.pdf:application/pdf},
}

@article{kruger_computational_2014,
	title = {Computational {State} {Space} {Models} for {Activity} and {Intention} {Recognition}. {A} {Feasibility} {Study}},
	volume = {9},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0109381},
	doi = {10.1371/journal.pone.0109381},
	abstract = {Background Computational state space models (CSSMs) enable the knowledge-based construction of Bayesian filters for recognizing intentions and reconstructing activities of human protagonists in application domains such as smart environments, assisted living, or security. Computational, i. e., algorithmic, representations allow the construction of increasingly complex human behaviour models. However, the symbolic models used in CSSMs potentially suffer from combinatorial explosion, rendering inference intractable outside of the limited experimental settings investigated in present research. The objective of this study was to obtain data on the feasibility of CSSM-based inference in domains of realistic complexity. Methods A typical instrumental activity of daily living was used as a trial scenario. As primary sensor modality, wearable inertial measurement units were employed. The results achievable by CSSM methods were evaluated by comparison with those obtained from established training-based methods (hidden Markov models, HMMs) using Wilcoxon signed rank tests. The influence of modeling factors on CSSM performance was analyzed via repeated measures analysis of variance. Results The symbolic domain model was found to have more than states, exceeding the complexity of models considered in previous research by at least three orders of magnitude. Nevertheless, if factors and procedures governing the inference process were suitably chosen, CSSMs outperformed HMMs. Specifically, inference methods used in previous studies (particle filters) were found to perform substantially inferior in comparison to a marginal filtering procedure. Conclusions Our results suggest that the combinatorial explosion caused by rich CSSM models does not inevitably lead to intractable inference or inferior performance. This means that the potential benefits of CSSM models (knowledge-based model construction, model reusability, reduced need for training data) are available without performance penalty. However, our results also show that research on CSSMs needs to consider sufficiently complex domains in order to understand the effects of design decisions such as choice of heuristics or inference procedure on performance.},
	language = {en},
	number = {11},
	urldate = {2022-07-26},
	journal = {PLOS ONE},
	author = {Krüger, Frank and Nyolt, Martin and Yordanova, Kristina and Hein, Albert and Kirste, Thomas},
	month = nov,
	year = {2014},
	note = {Publisher: Public Library of Science},
	keywords = {Random variables, Activities of daily living, Algorithms, Dynamical systems, Hidden Markov models, Language, Simulation and modeling, Statistical models, Symbolic Reasoning},
	pages = {e109381},
	file = {Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\INVVNB6D\\Krüger et al. - 2014 - Computational State Space Models for Activity and .pdf:application/pdf;Snapshot:C\:\\Users\\bened\\Zotero\\storage\\6F94EGX4\\article.html:text/html},
}

@inproceedings{papamakarios_masked_2017,
	title = {Masked {Autoregressive} {Flow} for {Density} {Estimation}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/6c1da886822c67822bcf3679d04369fa-Abstract.html},
	abstract = {Autoregressive models are among the best performing neural density estimators. We describe an approach for increasing the flexibility of an autoregressive model, based on modelling the random numbers that the model uses internally when generating data. By constructing a stack of autoregressive models, each modelling the random numbers of the next model in the stack, we obtain a type of normalizing flow suitable for density estimation, which we call Masked Autoregressive Flow. This type of flow is closely related to Inverse Autoregressive Flow and is a generalization of Real NVP. Masked Autoregressive Flow achieves state-of-the-art performance in a range of general-purpose density estimation tasks.},
	urldate = {2022-07-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Papamakarios, George and Pavlakou, Theo and Murray, Iain},
	year = {2017},
	file = {Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\7PJUIWRN\\Papamakarios et al. - 2017 - Masked Autoregressive Flow for Density Estimation.pdf:application/pdf},
}

@inproceedings{ramirez_goal_2011,
	title = {Goal {Recognition} over {POMDPs}: {Inferring} the {Intention} of a {POMDP} {Agent}},
	abstract = {Plan recognition is the problem of inferring the goals and plans of an agent from partial observations of her behavior. Recently, it has been shown that the problem can be formulated and solved using planners, reducing plan recognition to plan generation. In this work, we extend this model-based approach to plan recognition to the POMDP setting, where actions are stochastic and states are partially observable. The task is to infer a probability distribution over the possible goals of an agent whose behavior results from a POMDP model. The POMDP model is shared between agent and observer except for the true goal of the agent that is hidden to the observer. The observations are action sequences O that may contain gaps as some or even most of the actions done by the agent may not be observed. We show that the posterior goal distribution P (G{\textbar}O) can be computed from the value function VG(b) over beliefs b generated by the POMDP planner for each possible goal G. Some extensions of the basic framework are discussed, and a number of experiments are reported.},
	language = {en},
	booktitle = {Twenty-second international joint conference on artificial intelligence},
	author = {Ramirez, Miquel and Geffner, Hector},
	year = {2011},
	pages = {6},
	file = {Ramirez and Geffner - Goal Recognition over POMDPs Inferring the Intent.pdf:C\:\\Users\\bened\\Zotero\\storage\\8A6CY3CQ\\Ramirez and Geffner - Goal Recognition over POMDPs Inferring the Intent.pdf:application/pdf},
}

@article{moya_rueda_convolutional_2018,
	title = {Convolutional {Neural} {Networks} for {Human} {Activity} {Recognition} {Using} {Body}-{Worn} {Sensors}},
	volume = {5},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2227-9709},
	url = {https://www.mdpi.com/2227-9709/5/2/26},
	doi = {10.3390/informatics5020026},
	abstract = {Human activity recognition (HAR) is a classification task for recognizing human movements. Methods of HAR are of great interest as they have become tools for measuring occurrences and durations of human actions, which are the basis of smart assistive technologies and manual processes analysis. Recently, deep neural networks have been deployed for HAR in the context of activities of daily living using multichannel time-series. These time-series are acquired from body-worn devices, which are composed of different types of sensors. The deep architectures process these measurements for finding basic and complex features in human corporal movements, and for classifying them into a set of human actions. As the devices are worn at different parts of the human body, we propose a novel deep neural network for HAR. This network handles sequence measurements from different body-worn devices separately. An evaluation of the architecture is performed on three datasets, the Oportunity, Pamap2, and an industrial dataset, outperforming the state-of-the-art. In addition, different network configurations will also be evaluated. We find that applying convolutions per sensor channel and per body-worn device improves the capabilities of convolutional neural network (CNNs).},
	language = {en},
	number = {2},
	urldate = {2022-07-26},
	journal = {Informatics},
	author = {Moya Rueda, Fernando and Grzeszick, René and Fink, Gernot A. and Feldhorst, Sascha and Ten Hompel, Michael},
	month = jun,
	year = {2018},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {convolutional neural networks, human activity recognition, multichannel time-series, order picking},
	pages = {26},
	file = {Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\RLES67LH\\Moya Rueda et al. - 2018 - Convolutional Neural Networks for Human Activity R.pdf:application/pdf;Snapshot:C\:\\Users\\bened\\Zotero\\storage\\ES6DX6EU\\26.html:text/html},
}

@inproceedings{rueda_combining_2019,
	title = {Combining {Symbolic} {Reasoning} and {Deep} {Learning} for {Human} {Activity} {Recognition}},
	doi = {10.1109/PERCOMW.2019.8730792},
	abstract = {Activity recognition (AR) plays an important role in situation aware systems. Recently, deep learning approaches have shown promising results in the field of AR. However, their predictions are overconfident even in cases when the action class is incorrectly recognized. Moreover, these approaches provide information about an action class but not about the user context, such as location and manipulation of objects. To address these problems, we propose a hybrid AR architecture that combines deep learning with symbolic models to provide more realistic estimation of the classes and additional contextual information. We test the approach on a cooking dataset, describing the preparation of carrots soup. The results show that the proposed approach performs comparable to state of the art deep models inferring additional contextual properties about the current activity. The proposed approach is a first attempt to bridge the gap between deep learning and symbolic modeling for AR.},
	booktitle = {2019 {IEEE} {International} {Conference} on {Pervasive} {Computing} and {Communications} {Workshops} ({PerCom} {Workshops})},
	author = {Rueda, Fernando Moya and Lüdtke, Stefan and Schröder, Max and Yordanova, Kristina and Kirste, Thomas and Fink, Gernot A.},
	month = mar,
	year = {2019},
	keywords = {Computational modeling, Context modeling, Activity recognition, Computer architecture, Deep learning, Feature extraction, Human Activity Recognition, Probabilistic logic, Symbolic Reasoning},
	pages = {22--27},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bened\\Zotero\\storage\\VYBWJPMG\\8730792.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\LZB55LBG\\Rueda et al. - 2019 - Combining Symbolic Reasoning and Deep Learning for.pdf:application/pdf},
}

@article{baker_action_2009,
	series = {Reinforcement learning and higher cognition},
	title = {Action understanding as inverse planning},
	volume = {113},
	issn = {0010-0277},
	url = {https://www.sciencedirect.com/science/article/pii/S0010027709001607},
	doi = {10.1016/j.cognition.2009.07.005},
	abstract = {Humans are adept at inferring the mental states underlying other agents’ actions, such as goals, beliefs, desires, emotions and other thoughts. We propose a computational framework based on Bayesian inverse planning for modeling human action understanding. The framework represents an intuitive theory of intentional agents’ behavior based on the principle of rationality: the expectation that agents will plan approximately rationally to achieve their goals, given their beliefs about the world. The mental states that caused an agent's behavior are inferred by inverting this model of rational planning using Bayesian inference, integrating the likelihood of the observed actions with the prior over mental states. This approach formalizes in precise probabilistic terms the essence of previous qualitative approaches to action understanding based on an “intentional stance” [Dennett, D. C. (1987). The intentional stance. Cambridge, MA: MIT Press] or a “teleological stance” [Gergely, G., Nádasdy, Z., Csibra, G., \& Biró, S. (1995). Taking the intentional stance at 12 months of age. Cognition, 56, 165–193]. In three psychophysical experiments using animated stimuli of agents moving in simple mazes, we assess how well different inverse planning models based on different goal priors can predict human goal inferences. The results provide quantitative evidence for an approximately rational inference mechanism in human goal inference within our simplified stimulus paradigm, and for the flexible nature of goal representations that human observers can adopt. We discuss the implications of our experimental results for human action understanding in real-world contexts, and suggest how our framework might be extended to capture other kinds of mental state inferences, such as inferences about beliefs, or inferring whether an entity is an intentional agent.},
	language = {en},
	number = {3},
	urldate = {2022-07-26},
	journal = {Cognition},
	author = {Baker, Chris L. and Saxe, Rebecca and Tenenbaum, Joshua B.},
	month = dec,
	year = {2009},
	keywords = {Action understanding, Bayesian models, Goal inference, Inverse reinforcement learning, Theory of mind},
	pages = {329--349},
	file = {ScienceDirect Snapshot:C\:\\Users\\bened\\Zotero\\storage\\AUHTHZIA\\S0010027709001607.html:text/html;Submitted Version:C\:\\Users\\bened\\Zotero\\storage\\UDB3ZMZL\\Baker et al. - 2009 - Action understanding as inverse planning.pdf:application/pdf},
}

@book{koller_probabilistic_2009,
	title = {Probabilistic {Graphical} {Models}: {Principles} and {Techniques}},
	isbn = {978-0-262-01319-2},
	shorttitle = {Probabilistic {Graphical} {Models}},
	abstract = {A general framework for constructing and using probabilistic models of complex systems that would enable a computer to use available information for making decisions.Most tasks require a person or an automated system to reason—to reach conclusions based on available information. The framework of probabilistic graphical models, presented in this book, provides a general approach for this task. The approach is model-based, allowing interpretable models to be constructed and then manipulated by reasoning algorithms. These models can also be learned automatically from data, allowing the approach to be used in cases where manually constructing a model is difficult or even impossible. Because uncertainty is an inescapable aspect of most real-world applications, the book focuses on probabilistic models, which make the uncertainty explicit and provide models that are more faithful to reality. Probabilistic Graphical Models discusses a variety of models, spanning Bayesian networks, undirected Markov networks, discrete and continuous models, and extensions to deal with dynamical systems and relational data. For each class of models, the text describes the three fundamental cornerstones: representation, inference, and learning, presenting both basic concepts and advanced techniques. Finally, the book considers the use of the proposed framework for causal reasoning and decision making under uncertainty. The main text in each chapter provides the detailed technical development of the key ideas. Most chapters also include boxes with additional material: skill boxes, which describe techniques; case study boxes, which discuss empirical cases related to the approach described in the text, including applications in computer vision, robotics, natural language understanding, and computational biology; and concept boxes, which present significant concepts drawn from the material in the chapter. Instructors (and readers) can group chapters in various combinations, from core topics to more technically advanced material, to suit their particular needs.},
	language = {en},
	publisher = {MIT Press},
	author = {Koller, Daphne and Friedman, Nir},
	month = jul,
	year = {2009},
	note = {Google-Books-ID: 7dzpHCHzNQ4C},
	keywords = {Computers / Artificial Intelligence / General},
}

@article{chen_sensor-based_2012,
	title = {Sensor-{Based} {Activity} {Recognition}},
	volume = {42},
	issn = {1558-2442},
	doi = {10.1109/TSMCC.2012.2198883},
	abstract = {Research on sensor-based activity recognition has, recently, made significant progress and is attracting growing attention in a number of disciplines and application domains. However, there is a lack of high-level overview on this topic that can inform related communities of the research state of the art. In this paper, we present a comprehensive survey to examine the development and current status of various aspects of sensor-based activity recognition. We first discuss the general rationale and distinctions of vision-based and sensor-based activity recognition. Then, we review the major approaches and methods associated with sensor-based activity monitoring, modeling, and recognition from which strengths and weaknesses of those approaches are highlighted. We make a primary distinction in this paper between data-driven and knowledge-driven approaches, and use this distinction to structure our survey. We also discuss some promising directions for future research.},
	number = {6},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {Chen, Liming and Hoey, Jesse and Nugent, Chris D. and Cook, Diane J. and Yu, Zhiwen},
	month = nov,
	year = {2012},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	keywords = {Data models, Hidden Markov models, Activity modeling, activity monitoring, activity recognition, Biomedical monitoring, dense sensing, Human factors, Monitoring, pervasive computing, Wearable sensors},
	pages = {790--808},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bened\\Zotero\\storage\\CDFEFCKX\\6208895.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\I4YA9HJL\\Chen et al. - 2012 - Sensor-Based Activity Recognition.pdf:application/pdf},
}

@misc{manhaeve_neural_2019,
	title = {Neural {Probabilistic} {Logic} {Programming} in {DeepProbLog}},
	url = {http://arxiv.org/abs/1907.08194},
	abstract = {We introduce DeepProbLog, a neural probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques of the underlying probabilistic logic programming language ProbLog can be adapted for the new language. We theoretically and experimentally demonstrate that DeepProbLog supports (i) both symbolic and subsymbolic representations and inference, (ii) program induction, (iii) probabilistic (logic) programming, and (iv) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples.},
	urldate = {2022-09-06},
	publisher = {arXiv},
	author = {Manhaeve, Robin and Dumančić, Sebastijan and Kimmig, Angelika and Demeester, Thomas and De Raedt, Luc},
	month = sep,
	year = {2019},
	note = {arXiv:1907.08194 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\H8WR9FPF\\Manhaeve et al. - 2019 - Neural Probabilistic Logic Programming in DeepProb.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\3VWEQSII\\1907.html:text/html},
}

@inproceedings{manhaeve_deepproblog_2018,
	title = {{DeepProbLog}: {Neural} {Probabilistic} {Logic} {Programming}},
	volume = {31},
	shorttitle = {{DeepProbLog}},
	url = {https://proceedings.neurips.cc/paper/2018/hash/dc5d637ed5e62c36ecb73b654b05ba2a-Abstract.html},
	abstract = {We introduce DeepProbLog, a probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques can be adapted for the new language. Our experiments demonstrate that DeepProbLog supports (i) both symbolic and subsymbolic representations and inference, (ii) program induction, (iii) probabilistic (logic) programming, and (iv) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples.},
	urldate = {2022-09-06},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Manhaeve, Robin and Dumancic, Sebastijan and Kimmig, Angelika and Demeester, Thomas and De Raedt, Luc},
	year = {2018},
	keywords = {Hybrid},
	file = {Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\IJJH8KTW\\Manhaeve et al. - 2018 - DeepProbLog Neural Probabilistic Logic Programmin.pdf:application/pdf},
}

@misc{hammerla_deep_2016,
	title = {Deep, {Convolutional}, and {Recurrent} {Models} for {Human} {Activity} {Recognition} using {Wearables}},
	url = {http://arxiv.org/abs/1604.08880},
	abstract = {Human activity recognition (HAR) in ubiquitous computing is beginning to adopt deep learning to substitute for well-established analysis techniques that rely on hand-crafted feature extraction and classification techniques. From these isolated applications of custom deep architectures it is, however, difficult to gain an overview of their suitability for problems ranging from the recognition of manipulative gestures to the segmentation and identification of physical activities like running or ascending stairs. In this paper we rigorously explore deep, convolutional, and recurrent approaches across three representative datasets that contain movement data captured with wearable sensors. We describe how to train recurrent approaches in this setting, introduce a novel regularisation approach, and illustrate how they outperform the state-of-the-art on a large benchmark dataset. Across thousands of recognition experiments with randomly sampled model configurations we investigate the suitability of each model for different tasks in HAR, explore the impact of hyperparameters using the fANOVA framework, and provide guidelines for the practitioner who wants to apply deep learning in their problem setting.},
	urldate = {2022-09-06},
	publisher = {arXiv},
	author = {Hammerla, Nils Y. and Halloran, Shane and Ploetz, Thomas},
	month = apr,
	year = {2016},
	note = {arXiv:1604.08880 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Human-Computer Interaction},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\RLIUPZKK\\Hammerla et al. - 2016 - Deep, Convolutional, and Recurrent Models for Huma.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\VXLG3B2U\\1604.html:text/html},
}

@inproceedings{riboni_unsupervised_2016,
	address = {Heidelberg Germany},
	title = {Unsupervised recognition of interleaved activities of daily living through ontological and probabilistic reasoning},
	isbn = {978-1-4503-4461-6},
	url = {https://dl.acm.org/doi/10.1145/2971648.2971691},
	doi = {10.1145/2971648.2971691},
	abstract = {Recognition of activities of daily living (ADLs) is an enabling technology for several ubiquitous computing applications. In this ﬁeld, most activity recognition systems rely on supervised learning methods to extract activity models from labeled datasets. An inherent problem of that approach consists in the acquisition of comprehensive activity datasets, which is expensive and may violate individuals’ privacy. The problem is particularly challenging when focusing on complex ADLs, which are characterized by large intra- and inter-personal variability of execution. In this paper, we propose an unsupervised method to recognize complex ADLs exploiting the semantics of activities, context data, and sensing devices. Through ontological reasoning, we derive semantic correlations among activities and sensor events. By matching observed sensor events with semantic correlations, a statistical reasoner formulates initial hypotheses about the occurred activities. Those hypotheses are reﬁned through probabilistic reasoning, exploiting semantic constraints derived from the ontology. Extensive experiments with real-world datasets show that the accuracy of our unsupervised method is comparable to the one of state of the art supervised approaches.},
	language = {en},
	urldate = {2022-09-06},
	booktitle = {Proceedings of the 2016 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Riboni, Daniele and Sztyler, Timo and Civitarese, Gabriele and Stuckenschmidt, Heiner},
	month = sep,
	year = {2016},
	keywords = {Symbolic Reasoning},
	pages = {1--12},
}

@article{ordonez_deep_2016,
	title = {Deep {Convolutional} and {LSTM} {Recurrent} {Neural} {Networks} for {Multimodal} {Wearable} {Activity} {Recognition}},
	volume = {16},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/16/1/115},
	doi = {10.3390/s16010115},
	abstract = {Human activity recognition (HAR) tasks have traditionally been solved using engineered features obtained by heuristic processes. Current research suggests that deep convolutional neural networks are suited to automate feature extraction from raw sensor inputs. However, human activities are made of complex sequences of motor movements, and capturing this temporal dynamics is fundamental for successful HAR. Based on the recent success of recurrent neural networks for time series domains, we propose a generic deep framework for activity recognition based on convolutional and LSTM recurrent units, which: (i) is suitable for multimodal wearable sensors; (ii) can perform sensor fusion naturally; (iii) does not require expert knowledge in designing features; and (iv) explicitly models the temporal dynamics of feature activations. We evaluate our framework on two datasets, one of which has been used in a public activity recognition challenge. Our results show that our framework outperforms competing deep non-recurrent networks on the challenge dataset by 4\% on average; outperforming some of the previous reported results by up to 9\%. Our results show that the framework can be applied to homogeneous sensor modalities, but can also fuse multimodal sensors to improve performance. We characterise key architectural hyperparameters’ influence on performance to provide insights about their optimisation.},
	language = {en},
	number = {1},
	urldate = {2022-09-06},
	journal = {Sensors},
	author = {Ordóñez, Francisco Javier and Roggen, Daniel},
	month = jan,
	year = {2016},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {deep learning, machine learning, human activity recognition, LSTM, neural network, sensor fusion, wearable sensors, Neural},
	pages = {115},
	file = {Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\UQHQU4LN\\Ordóñez and Roggen - 2016 - Deep Convolutional and LSTM Recurrent Neural Netwo.pdf:application/pdf;Snapshot:C\:\\Users\\bened\\Zotero\\storage\\6W26NBKL\\html.html:text/html},
}

@misc{yao_efficient_2017,
	title = {Efficient {Dense} {Labeling} of {Human} {Activity} {Sequences} from {Wearables} using {Fully} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1702.06212},
	abstract = {Recognizing human activities in a sequence is a challenging area of research in ubiquitous computing. Most approaches use a fixed size sliding window over consecutive samples to extract features---either handcrafted or learned features---and predict a single label for all samples in the window. Two key problems emanate from this approach: i) the samples in one window may not always share the same label. Consequently, using one label for all samples within a window inevitably lead to loss of information; ii) the testing phase is constrained by the window size selected during training while the best window size is difficult to tune in practice. We propose an efficient algorithm that can predict the label of each sample, which we call dense labeling, in a sequence of human activities of arbitrary length using a fully convolutional network. In particular, our approach overcomes the problems posed by the sliding window step. Additionally, our algorithm learns both the features and classifier automatically. We release a new daily activity dataset based on a wearable sensor with hospitalized patients. We conduct extensive experiments and demonstrate that our proposed approach is able to outperform the state-of-the-arts in terms of classification and label misalignment measures on three challenging datasets: Opportunity, Hand Gesture, and our new dataset.},
	urldate = {2022-09-06},
	publisher = {arXiv},
	author = {Yao, Rui and Lin, Guosheng and Shi, Qinfeng and Ranasinghe, Damith},
	month = feb,
	year = {2017},
	note = {arXiv:1702.06212 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Human-Computer Interaction, neural network},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\GYMBRTHH\\Yao et al. - 2017 - Efficient Dense Labeling of Human Activity Sequenc.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\E7P5UG2P\\1702.html:text/html},
}

@article{chen_deep_2022,
	title = {Deep {Learning} for {Sensor}-based {Human} {Activity} {Recognition}: {Overview}, {Challenges}, and {Opportunities}},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Deep {Learning} for {Sensor}-based {Human} {Activity} {Recognition}},
	url = {https://dl.acm.org/doi/10.1145/3447744},
	doi = {10.1145/3447744},
	abstract = {The vast proliferation of sensor devices and Internet of Things enables the applications of sensor-based activity recognition. However, there exist substantial challenges that could influence the performance of the recognition system in practical scenarios. Recently, as deep learning has demonstrated its effectiveness in many areas, plenty of deep methods have been investigated to address the challenges in activity recognition. In this study, we present a survey of the state-of-the-art deep learning methods for sensor-based human activity recognition. We first introduce the multi-modality of the sensory data and provide information for public datasets that can be used for evaluation in different challenge tasks. We then propose a new taxonomy to structure the deep methods by challenges. Challenges and challenge-related deep methods are summarized and analyzed to form an overview of the current research progress. At the end of this work, we discuss the open issues and provide some insights for future directions.},
	language = {en},
	number = {4},
	urldate = {2022-09-06},
	journal = {ACM Computing Surveys},
	author = {Chen, Kaixuan and Zhang, Dalin and Yao, Lina and Guo, Bin and Yu, Zhiwen and Liu, Yunhao},
	month = may,
	year = {2022},
	keywords = {Deep Neural Network, neural network},
	pages = {1--40},
	file = {Chen et al. - 2022 - Deep Learning for Sensor-based Human Activity Reco.pdf:C\:\\Users\\bened\\Zotero\\storage\\GJMREEQM\\Chen et al. - 2022 - Deep Learning for Sensor-based Human Activity Reco.pdf:application/pdf},
}

@article{shavit_boosting_2021,
	title = {Boosting {Inertial}-{Based} {Human} {Activity} {Recognition} {With} {Transformers}},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3070646},
	abstract = {Activity recognition problems such as human activity recognition and smartphone location recognition can improve the accuracy of different navigation or healthcare tasks, which rely solely on inertial sensors. Current learning-based approaches for activity recognition from inertial data employ convolutional neural networks or long short term memory architectures. Recently, Transformers were shown to outperform these architectures for sequence analysis tasks. This work presents an activity recognition model based on Transformers which offers an improved and general framework for learning activity recognition tasks. For evaluation purposes, several datasets, with more than 27 hours of inertial data recordings collected by 91 users, are employed. Those datasets represent different user activity scenarios with varying difficulty. The proposed approach consistently achieves better accuracy and generalizes better across all examined datasets and scenarios. A codebase implementing the described framework is available at: https://github.com/yolish/har-with-imu-transformer.},
	journal = {IEEE Access},
	author = {Shavit, Yoli and Klein, Itzik},
	year = {2021},
	note = {Conference Name: IEEE Access},
	keywords = {Neural networks, convolutional neural networks, Activity recognition, Accelerometers, Belts, Human activity recognition, inertial sensors, Legged locomotion, Magnetic heads, pedestrian dead reckoning, sequence analysis, smartphone location recognition, Stairs, Task analysis, Transformers},
	pages = {53540--53547},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bened\\Zotero\\storage\\2ILDIDEB\\9393889.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\JZ43EPP4\\Shavit and Klein - 2021 - Boosting Inertial-Based Human Activity Recognition.pdf:application/pdf},
}

@inproceedings{sztyler_modeling_2018,
	title = {Modeling and {Reasoning} with {ProbLog}: {An} {Application} in {Recognizing} {Complex} {Activities}},
	shorttitle = {Modeling and {Reasoning} with {ProbLog}},
	doi = {10.1109/PERCOMW.2018.8480299},
	abstract = {Smart-home activity recognition is an enabling tool for a wide range of ambient assisted living applications. The recognition of ADLs usually relies on supervised learning or knowledge-based reasoning techniques. In order to overcome the well-known limitations of those two approaches and, at the same time, to combine their strengths to improve the recognition rate, many researchers investigated Markov Logic Networks (MLNs). However, MLNs require a non-trivial effort by experts to properly model probabilities in terms of weights. In this paper, we propose a novel method based on ProbLog. ProbLog is a probabilistic extension of Prolog, which allows to explicitly define probabilistic facts and rules. With respect to MLN, the inference mode of ProbLog is based on the closed-world assumption and it has faster response times. We propose a simple and flexible ProbLog model, which we exploit to recognize complex ADLs in an online fashion. Considering a dataset with 21 subjects, our results show that our method reaches high F-measure (83\%). Moreover, we also show that the response time of ProbLog is satisfying for real-time applications.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Pervasive} {Computing} and {Communications} {Workshops} ({PerCom} {Workshops})},
	author = {Sztyler, Timo and Civitarese, Gabriele and Stuckenschmidt, Heiner},
	month = mar,
	year = {2018},
	keywords = {Context modeling, Random variables, Activity recognition, Probabilistic logic, Symbolic Reasoning, Knowledge based systems, Sensor phenomena and characterization},
	pages = {259--264},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bened\\Zotero\\storage\\852NSZ5E\\8480299.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\CET8DBJW\\Sztyler et al. - 2018 - Modeling and Reasoning with ProbLog An Applicatio.pdf:application/pdf},
}

@misc{ludtke_lifted_2018,
	title = {Lifted {Filtering} via {Exchangeable} {Decomposition}},
	url = {http://arxiv.org/abs/1801.10495},
	abstract = {We present a model for exact recursive Bayesian filtering based on lifted multiset states. Combining multisets with lifting makes it possible to simultaneously exploit multiple strategies for reducing inference complexity when compared to list-based grounded state representations. The core idea is to borrow the concept of Maximally Parallel Multiset Rewriting Systems and to enhance it by concepts from Rao-Blackwellization and Lifted Inference, giving a representation of state distributions that enables efficient inference. In worlds where the random variables that define the system state are exchangeable -- where the identity of entities does not matter -- it automatically uses a representation that abstracts from ordering (achieving an exponential reduction in complexity) -- and it automatically adapts when observations or system dynamics destroy exchangeability by breaking symmetry.},
	urldate = {2022-09-06},
	publisher = {arXiv},
	author = {Lüdtke, Stefan and Schröder, Max and Bader, Sebastian and Kersting, Kristian and Kirste, Thomas},
	month = may,
	year = {2018},
	note = {arXiv:1801.10495 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Symbolic Reasoning},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\XQ8NKNFL\\Lüdtke et al. - 2018 - Lifted Filtering via Exchangeable Decomposition.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\PYTQX7GM\\1801.html:text/html},
}

@article{civitarese_polaris_2021,
	title = {{POLARIS}: {Probabilistic} and {Ontological} {Activity} {Recognition} in {Smart}-{Homes}},
	volume = {33},
	issn = {1558-2191},
	shorttitle = {{POLARIS}},
	doi = {10.1109/TKDE.2019.2930050},
	abstract = {Recognition of activities of daily living (ADLs) is an enabling technology for several ubiquitous computing applications. Most activity recognition systems rely on supervised learning to extract activity models from labeled datasets. A problem with that approach is the acquisition of comprehensive activity datasets, which is an expensive task. The problem is particularly challenging when focusing on complex ADLs characterized by large variability of execution. Moreover, several activity recognition systems are limited to offline recognition, while many applications claim for online activity recognition. In this paper, we propose POLARIS, a framework for unsupervised activity recognition. POLARIS can recognize complex ADLs exploiting the semantics of activities, context data, and sensors. Through ontological reasoning, our algorithm derives semantic correlations among activities and sensor events. By matching observed events with semantic correlations, a statistical reasoner formulates initial hypotheses about the occurred activities. Those hypotheses are refined through probabilistic reasoning, exploiting semantic constraints derived from the ontology. Our system supports online recognition, thanks to a novel segmentation algorithm. Extensive experiments with real-world datasets show that the accuracy of our unsupervised method is comparable to the one of supervised approaches. Moreover, the online version of our system achieves essentially the same accuracy of the offline version.},
	number = {1},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Civitarese, Gabriele and Sztyler, Timo and Riboni, Daniele and Bettini, Claudio and Stuckenschmidt, Heiner},
	month = jan,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	keywords = {Ontologies, Activity recognition, Probabilistic logic, Symbolic Reasoning, pervasive computing, Correlation, online/offline activity recognition, Ontological reasoning, probabilistic reasoning, Semantics, unsupervised classification},
	pages = {209--223},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bened\\Zotero\\storage\\4MPH7G8B\\8769915.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\8TDT3IQR\\Civitarese et al. - 2021 - POLARIS Probabilistic and Ontological Activity Re.pdf:application/pdf},
}

@misc{garcez_neurosymbolic_2020,
	title = {Neurosymbolic {AI}: {The} 3rd {Wave}},
	shorttitle = {Neurosymbolic {AI}},
	url = {http://arxiv.org/abs/2012.05876},
	abstract = {Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.},
	urldate = {2022-09-06},
	publisher = {arXiv},
	author = {Garcez, Artur d'Avila and Lamb, Luis C.},
	month = dec,
	year = {2020},
	note = {arXiv:2012.05876 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Neuro-symbolic, Hybrid, Overview},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\A5H744GJ\\Garcez and Lamb - 2020 - Neurosymbolic AI The 3rd Wave.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\9SBA23SG\\2012.html:text/html},
}

@misc{ludtke_human_2021,
	title = {Human {Activity} {Recognition} using {Attribute}-{Based} {Neural} {Networks} and {Context} {Information}},
	url = {http://arxiv.org/abs/2111.04564},
	abstract = {We consider human activity recognition (HAR) from wearable sensor data in manual-work processes, like warehouse order-picking. Such structured domains can often be partitioned into distinct process steps, e.g., packaging or transporting. Each process step can have a different prior distribution over activity classes, e.g., standing or walking, and different system dynamics. Here, we show how such context information can be integrated systematically into a deep neural network-based HAR system. Specifically, we propose a hybrid architecture that combines a deep neural network-that estimates high-level movement descriptors, attributes, from the raw-sensor data-and a shallow classifier, which predicts activity classes from the estimated attributes and (optional) context information, like the currently executed process step. We empirically show that our proposed architecture increases HAR performance, compared to state-of-the-art methods. Additionally, we show that HAR performance can be further increased when information about process steps is incorporated, even when that information is only partially correct.},
	urldate = {2022-09-06},
	publisher = {arXiv},
	author = {Lüdtke, Stefan and Rueda, Fernando Moya and Ahmed, Waqas and Fink, Gernot A. and Kirste, Thomas},
	month = oct,
	year = {2021},
	note = {arXiv:2111.04564 [cs, eess]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\93HXTXAW\\Lüdtke et al. - 2021 - Human Activity Recognition using Attribute-Based N.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\TUKE27GG\\2111.html:text/html},
}

@article{germain_made_nodate,
	title = {{MADE}: {Masked} {Autoencoder} for {Distribution} {Estimation}},
	abstract = {There has been a lot of recent interest in designing neural network models to estimate a distribution from a set of examples. We introduce a simple modiﬁcation for autoencoder neural networks that yields powerful generative models. Our method masks the autoencoder’s parameters to respect autoregressive constraints: each input is reconstructed only from previous inputs in a given ordering. Constrained this way, the autoencoder outputs can be interpreted as a set of conditional probabilities, and their product, the full joint probability. We can also train a single network that can decompose the joint probability in multiple different orderings. Our simple framework can be applied to multiple architectures, including deep ones. Vectorized implementations, such as on GPUs, are simple and fast. Experiments demonstrate that this approach is competitive with stateof-the-art tractable distribution estimators. At test time, the method is signiﬁcantly faster and scales better than other autoregressive estimators.},
	language = {en},
	author = {Germain, Mathieu and Gregor, Karol and Murray, Iain and Larochelle, Hugo},
	year = {2015},
	pages = {9},
	file = {Germain et al. - MADE Masked Autoencoder for Distribution Estimati.pdf:C\:\\Users\\bened\\Zotero\\storage\\FC2KU8HM\\Germain et al. - MADE Masked Autoencoder for Distribution Estimati.pdf:application/pdf},
}

@inproceedings{schmah_generative_2008,
	title = {Generative versus discriminative training of {RBMs} for classification of {fMRI} images},
	volume = {21},
	url = {https://proceedings.neurips.cc/paper/2008/hash/3e77a14629775492504515dc4b23deda-Abstract.html},
	abstract = {Neuroimaging datasets often have a very large number of voxels and a very small number of training cases, which means that overfitting of models for this data can become a very serious problem. Working with a set of fMRI images from a study on stroke recovery, we consider a classification task for which logistic regression performs poorly, even when L1- or L2- regularized. We show that much better discrimination can be achieved by fitting a generative model to each separate condition and then seeing which model is most likely to have generated the data. We compare discriminative training of exactly the same set of models, and we also consider convex blends of generative and discriminative training.},
	urldate = {2022-09-07},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Schmah, Tanya and Hinton, Geoffrey E and Small, Steven and Strother, Stephen and Zemel, Richard},
	year = {2008},
	keywords = {Background},
	file = {Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\XTDLAECF\\Schmah et al. - 2008 - Generative versus discriminative training of RBMs .pdf:application/pdf},
}

@article{raedt_problog_nodate,
	title = {{ProbLog}: {A} {Probabilistic} {Prolog} and {Its} {Application} in {Link} {Discovery}},
	abstract = {We introduce ProbLog, a probabilistic extension of Prolog. A ProbLog program deﬁnes a distribution over logic programs by specifying for each clause the probability that it belongs to a randomly sampled program, and these probabilities are mutually independent. The semantics of ProbLog is then deﬁned by the success probability of a query, which corresponds to the probability that the query succeeds in a randomly sampled program. The key contribution of this paper is the introduction of an effective solver for computing success probabilities. It essentially combines SLD-resolution with methods for computing the probability of Boolean formulae. Our implementation further employs an approximation algorithm that combines iterative deepening with binary decision diagrams. We report on experiments in the context of discovering links in real biological networks, a demonstration of the practical usefulness of the approach.},
	language = {en},
	author = {Raedt, Luc De},
	pages = {6},
	file = {Raedt - ProbLog A Probabilistic Prolog and Its Applicatio.pdf:C\:\\Users\\bened\\Zotero\\storage\\G5ANZRXE\\Raedt - ProbLog A Probabilistic Prolog and Its Applicatio.pdf:application/pdf},
}

@inproceedings{arrotta_knowledge_2022,
	title = {Knowledge {Infusion} for {Context}-{Aware} {Sensor}-{Based} {Human} {Activity} {Recognition}},
	doi = {10.1109/SMARTCOMP55677.2022.00016},
	abstract = {Neuro-symbolic AI methods aim at integrating the capabilities of data-driven deep learning solutions with the ones of more traditional symbolic approaches. These techniques have been poorly explored in the sensor-based Human Activity Recognition (HAR) research field, even if they could lead to multiple benefits such as improving model interpretability and reducing the amount of labeled data that is necessary to reliably train the model. In this paper, we propose DUSTIN, a novel knowledge infusion approach for sensor-based HAR. DUSTIN concatenates the features automatically extracted by a CNN model from raw sensor data and high-level context data with the ones inferred by a knowledge-based reasoner. In particular, the symbolic features encode common-sense knowledge about the activities which are consistent with the context of the user, and they are infused within the model before the classification layer. We experimentally evaluated DUSTIN on a HAR dataset of mobile devices sensor data that includes 14 different activities performed by 26 users. Our results show that DUSTIN outperforms state-of-the-art neuro-symbolic approaches, with the advantage of requiring a limited amount of training data and training epochs to reach satisfying recognition rates.},
	booktitle = {2022 {IEEE} {International} {Conference} on {Smart} {Computing} ({SMARTCOMP})},
	author = {Arrotta, Luca and Civitarese, Gabriele and Bettini, Claudio},
	month = jun,
	year = {2022},
	note = {ISSN: 2693-8340},
	keywords = {Data models, neuro-symbolic AI, Training, Neural networks, Ontologies, Deep learning, Feature extraction, activity recognition, Knowledge engineering, knowledge infusion, hybrid},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bened\\Zotero\\storage\\BXLFZRTH\\9821036.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\LFCA75HV\\Arrotta et al. - 2022 - Knowledge Infusion for Context-Aware Sensor-Based .pdf:application/pdf},
}

@article{sukor_hybrid_2019,
	title = {A hybrid approach of knowledge-driven and data-driven reasoning for activity recognition in smart homes},
	volume = {36},
	issn = {10641246, 18758967},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/JIFS-169976},
	doi = {10.3233/JIFS-169976},
	abstract = {Accurate activity recognition plays a major role in smart homes to provide assistance and support for users, especially elderly and cognitively impaired people. To realize this task, knowledge-driven approaches are one of the emerging research areas that have shown interesting advantages and features. However, several limitations have been associated with these approaches. The produced models are usually incomplete to capture all types of human activities. This resulted in the limited ability to accurately infer users’ activities. This paper presents an alternative approach by combining knowledge-driven with data-driven reasoning to allow activity models to evolve and adapt automatically based on users’ particularities. Firstly, a knowledge-driven reasoning is presented for inferring an initial activity model. The model is then trained using data-driven techniques to produce a dynamic activity model that learns users’ varying action. This approach has been evaluated using a publicly available dataset and the experimental results show the learned activity model yields signiﬁcantly higher recognition rates compared to the initial activity model.},
	language = {en},
	number = {5},
	urldate = {2022-11-24},
	journal = {Journal of Intelligent \& Fuzzy Systems},
	author = {Sukor, Abdul Syafiq Abdull and Zakaria, Ammar and Rahim, Norasmadi Abdul and Kamarudin, Latifah Munirah and Setchi, Rossi and Nishizaki, Hiromitsu},
	editor = {Vijayakumar, V. and Subramaniyaswamy, V. and Abawajy, Jemal and Yang, Longzhi},
	month = may,
	year = {2019},
	pages = {4177--4188},
	file = {Sukor et al. - 2019 - A hybrid approach of knowledge-driven and data-dri.pdf:C\:\\Users\\bened\\Zotero\\storage\\ME2Y5CTS\\Sukor et al. - 2019 - A hybrid approach of knowledge-driven and data-dri.pdf:application/pdf},
}

@article{bettini_caviar_2020,
	title = {{CAVIAR}: {Context}-driven {Active} and {Incremental} {Activity} {Recognition}},
	volume = {196},
	issn = {09507051},
	shorttitle = {{CAVIAR}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705120301969},
	doi = {10.1016/j.knosys.2020.105816},
	abstract = {Activity recognition on mobile device sensor data has been an active research area in mobile and pervasive computing for several years. While the majority of the proposed techniques are based on supervised learning, semi-supervised approaches are being considered to reduce the size of the training set required to initialize the model. These approaches usually apply self-training or active learning to incrementally reﬁne the model, but their eﬀectiveness seems to be limited to a restricted set of physical activities. We claim that the context which surrounds the user (e.g., time, location, proximity to transportation routes) combined with common knowledge about the relationship between context and human activities could be eﬀective in signiﬁcantly increasing the set of recognized activities including those that are diﬃcult to discriminate only considering inertial sensors, and the highly context-dependent ones. In this paper, we propose CAVIAR, a novel hybrid semi-supervised and knowledge-based system for real-time activity recognition. Our method applies semantic reasoning on contextdata to reﬁne the predictions of an incremental classiﬁer. The recognition model is continuously updated using active learning. Results on a real dataset obtained from 26 subjects show the eﬀectiveness of our approach in increasing the recognition rate, extending the number of recognizable activities and, most importantly, reducing the number of queries triggered by active learning. In order to evaluate the impact of context reasoning, we also compare CAVIAR with a purely statistical version, considering features computed on context-data as part of the machine learning process.},
	language = {en},
	urldate = {2022-11-24},
	journal = {Knowledge-Based Systems},
	author = {Bettini, Claudio and Civitarese, Gabriele and Presotto, Riccardo},
	month = may,
	year = {2020},
	pages = {105816},
	file = {Bettini et al. - 2020 - CAVIAR Context-driven Active and Incremental Acti.pdf:C\:\\Users\\bened\\Zotero\\storage\\V5XAJMXQ\\Bettini et al. - 2020 - CAVIAR Context-driven Active and Incremental Acti.pdf:application/pdf},
}


@misc{kostrikov_pytorch-flows_2022,
	title = {pytorch-flows},
	copyright = {MIT},
	url = {https://github.com/ikostrikov/pytorch-flows},
	abstract = {PyTorch implementations of algorithms for density estimation},
	urldate = {2023-01-02},
	author = {Kostrikov, Ilya},
	month = dec,
	year = {2022},
	note = {original-date: 2018-09-01T19:58:17Z},
	keywords = {deep-learning, density-estimation, neural-networks, probabilities, pytorch},
}

@inproceedings{anguita_public_2013,
	address = {Bruges, Belgium},
	title = {A {Public} {Domain} {Dataset} for {Human} {Activity} {Recognition} {Using} {Smartphones}},
	booktitle = {21th {European} {Symposium} on {Artificial} {Neural} {Networks}, {Computational} {Intelligence} and {Machine} {Learning}},
	author = {Anguita, Davide and Ghio, Alessandro and Oneto, Luca and Parra, Xavier and Reyes-Ortiz, Jorge L.},
	month = apr,
	year = {2013},
}

@inproceedings{malekzadeh_mobile_2019,
	address = {Montreal, Quebec, Canada},
	title = {Mobile {Sensor} {Data} {Anonymization}},
	isbn = {978-1-4503-6283-2},
	url = {http://doi.acm.org/10.1145/3302505.3310068},
	doi = {10.1145/3302505.3310068},
	booktitle = {Proceedings of the {International} {Conference} on {Internet} of {Things} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Malekzadeh, Mohammad and Clegg, Richard G. and Cavallaro, Andrea and Haddadi, Hamed},
	year = {2019},
	pages = {49--58},
}

@misc{kruger_recognising_2011,
	title = {Recognising user actions during cooking task ({Cooking} task dataset) : {IMU} {Data}},
	copyright = {CC BY 4.0},
	shorttitle = {Recognising user actions during cooking task ({Cooking} task dataset)},
	url = {https://rosdok.uni-rostock.de/resolve/id/rosdok_document_0000010639},
	abstract = {The dataset contains the data of acceleration sensors attached to a person during the execution of a kitchen task. It consists of 7 datasets that describe the execution of preparing and having a meal: preparing the ingredients, cooking, serving the meal, having a meal, cleaning the table, and washing the dishes. Each of these datasets consists of the raw acceleration and angular rates that were recorded with motion capturing system based on wearable inertial measurement units (IMUs).The aim of the experiment is to investigate the ability of activity recognition approaches to recognise fine-grained user activities based on acceleration data. The results from the dataset can be found in the PlosOne paper "Computational State Space Models for Activity and Intention Recognition. A Feasibility Study" by Krüger et al.},
	urldate = {2023-01-03},
	author = {Krüger, Frank and Hein, Albert and Yordanova, Kristina and Kirste, Thomas},
	year = {2011},
	note = {Publisher: University of Rostock Rostock},
	file = {Snapshot:C\:\\Users\\bened\\Zotero\\storage\\MJ8EQNNB\\rosdok_document_0000010639.html:text/html},
}

@inproceedings{um_data_2017,
	title = {Data {Augmentation} of {Wearable} {Sensor} {Data} for {Parkinson}'s {Disease} {Monitoring} using {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1706.00527},
	doi = {10.1145/3136755.3136817},
	abstract = {While convolutional neural networks (CNNs) have been successfully applied to many challenging classification applications, they typically require large datasets for training. When the availability of labeled data is limited, data augmentation is a critical preprocessing step for CNNs. However, data augmentation for wearable sensor data has not been deeply investigated yet. In this paper, various data augmentation methods for wearable sensor data are proposed. The proposed methods and CNNs are applied to the classification of the motor state of Parkinson's Disease patients, which is challenging due to small dataset size, noisy labels, and large intra-class variability. Appropriate augmentation improves the classification performance from 77.54{\textbackslash}\% to 86.88{\textbackslash}\%.},
	urldate = {2023-01-03},
	booktitle = {Proceedings of the 19th {ACM} {International} {Conference} on {Multimodal} {Interaction}},
	author = {Um, Terry Taewoong and Pfister, Franz Michael Josef and Pichler, Daniel and Endo, Satoshi and Lang, Muriel and Hirche, Sandra and Fietzek, Urban and Kulić, Dana},
	month = nov,
	year = {2017},
	note = {arXiv:1706.00527 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {216--220},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\F52QKR9I\\Um et al. - 2017 - Data Augmentation of Wearable Sensor Data for Park.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\2ZZ3AQ3U\\1706.html:text/html},
}


@inproceedings{eldele_time-series_2021,
	address = {Montreal, Canada},
	title = {Time-{Series} {Representation} {Learning} via {Temporal} and {Contextual} {Contrasting}},
	isbn = {978-0-9992411-9-6},
	url = {https://www.ijcai.org/proceedings/2021/324},
	doi = {10.24963/ijcai.2021/324},
	abstract = {Learning decent representations from unlabeled time-series data with temporal dynamics is a very challenging task. In this paper, we propose an unsupervised Time-Series representation learning framework via Temporal and Contextual Contrasting (TS-TCC), to learn time-series representation from unlabeled data. First, the raw timeseries data are transformed into two different yet correlated views by using weak and strong augmentations. Second, we propose a novel temporal contrasting module to learn robust temporal representations by designing a tough cross-view prediction task. Last, to further learn discriminative representations, we propose a contextual contrasting module built upon the contexts from the temporal contrasting module. It attempts to maximize the similarity among different contexts of the same sample while minimizing similarity among contexts of different samples. Experiments have been carried out on three real-world time-series datasets. The results manifest that training a linear classiﬁer on top of the features learned by our proposed TS-TCC performs comparably with the supervised training. Additionally, our proposed TS-TCC shows high efﬁciency in few-labeled data and transfer learning scenarios. The code is publicly available at https://github.com/emadeldeen24/TS-TCC.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {Proceedings of the {Thirtieth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Eldele, Emadeldeen and Ragab, Mohamed and Chen, Zhenghua and Wu, Min and Kwoh, Chee Keong and Li, Xiaoli and Guan, Cuntai},
	month = aug,
	year = {2021},
	pages = {2352--2359},
	file = {Eldele et al. - 2021 - Time-Series Representation Learning via Temporal a.pdf:C\:\\Users\\bened\\Zotero\\storage\\D235HWHX\\Eldele et al. - 2021 - Time-Series Representation Learning via Temporal a.pdf:application/pdf},
}

@misc{dinh_density_2017,
	title = {Density estimation using {Real} {NVP}},
	url = {http://arxiv.org/abs/1605.08803},
	doi = {10.48550/arXiv.1605.08803},
	abstract = {Unsupervised learning of probabilistic models is a central yet challenging problem in machine learning. Specifically, designing models with tractable learning, sampling, inference and evaluation is crucial in solving this task. We extend the space of such models using real-valued non-volume preserving (real NVP) transformations, a set of powerful invertible and learnable transformations, resulting in an unsupervised learning algorithm with exact log-likelihood computation, exact sampling, exact inference of latent variables, and an interpretable latent space. We demonstrate its ability to model natural images on four datasets through sampling, log-likelihood evaluation and latent variable manipulations.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
	month = feb,
	year = {2017},
	note = {arXiv:1605.08803 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\9QCJGF8A\\Dinh et al. - 2017 - Density estimation using Real NVP.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\2GGAF7BE\\1605.html:text/html},
}

@misc{kingma_glow_2018,
	title = {Glow: {Generative} {Flow} with {Invertible} 1x1 {Convolutions}},
	shorttitle = {Glow},
	url = {http://arxiv.org/abs/1807.03039},
	doi = {10.48550/arXiv.1807.03039},
	abstract = {Flow-based generative models (Dinh et al., 2014) are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using an invertible 1x1 convolution. Using our method we demonstrate a significant improvement in log-likelihood on standard benchmarks. Perhaps most strikingly, we demonstrate that a generative model optimized towards the plain log-likelihood objective is capable of efficient realistic-looking synthesis and manipulation of large images. The code for our model is available at https://github.com/openai/glow},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Dhariwal, Prafulla},
	month = jul,
	year = {2018},
	note = {arXiv:1807.03039 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\K92LQSEX\\Kingma and Dhariwal - 2018 - Glow Generative Flow with Invertible 1x1 Convolut.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\FS2BKF8X\\1807.html:text/html},
}


