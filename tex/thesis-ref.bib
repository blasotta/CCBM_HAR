
@inproceedings{gens_learning_2013,
	title = {Learning the {Structure} of {Sum}-{Product} {Networks}},
	abstract = {Sum-product networks (SPNs) are a new class of deep probabilistic models. SPNs can have unbounded treewidth but inference in them is always tractable. An SPN is either a univariate distribution, a product of SPNs over disjoint variables, or a weighted sum of SPNs over the same variables. We propose the ﬁrst algorithm for learning the structure of SPNs that takes full advantage of their expressiveness. At each step, the algorithm attempts to divide the current variables into approximately independent subsets. If successful, it returns the product of recursive calls on the subsets; otherwise it returns the sum of recursive calls on subsets of similar instances from the current training set. A comprehensive empirical study shows that the learned SPNs are typically comparable to graphical models in likelihood but superior in inference speed and accuracy.},
	language = {en},
	booktitle = {{PMLR}},
	author = {Gens, Robert and Domingos, Pedro},
	year = {2013},
	pages = {873--880},
	file = {Gens and Domingos - Learning the Structure of Sum-Product Networks.pdf:C\:\\Users\\bened\\Zotero\\storage\\YCQW6ZE3\\Gens and Domingos - Learning the Structure of Sum-Product Networks.pdf:application/pdf},
}

@article{kobyzev_normalizing_2021,
	title = {Normalizing {Flows}: {An} {Introduction} and {Review} of {Current} {Methods}},
	volume = {43},
	issn = {1939-3539},
	shorttitle = {Normalizing {Flows}},
	doi = {10.1109/TPAMI.2020.2992934},
	abstract = {Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.},
	number = {11},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Kobyzev, Ivan and Prince, Simon J.D. and Brubaker, Marcus A.},
	month = nov,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Training, Computational modeling, Context modeling, density estimation, Estimation, Generative models, invertible neural networks, Jacobian matrices, Mathematical model, normalizing flows, Random variables, variational inference},
	pages = {3964--3979},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bened\\Zotero\\storage\\VKBTAVUN\\9089305.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\3H2Q3XXV\\Kobyzev et al. - 2021 - Normalizing Flows An Introduction and Review of C.pdf:application/pdf},
}

@article{kruger_computational_2014,
	title = {Computational {State} {Space} {Models} for {Activity} and {Intention} {Recognition}. {A} {Feasibility} {Study}},
	volume = {9},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0109381},
	doi = {10.1371/journal.pone.0109381},
	abstract = {Background Computational state space models (CSSMs) enable the knowledge-based construction of Bayesian filters for recognizing intentions and reconstructing activities of human protagonists in application domains such as smart environments, assisted living, or security. Computational, i. e., algorithmic, representations allow the construction of increasingly complex human behaviour models. However, the symbolic models used in CSSMs potentially suffer from combinatorial explosion, rendering inference intractable outside of the limited experimental settings investigated in present research. The objective of this study was to obtain data on the feasibility of CSSM-based inference in domains of realistic complexity. Methods A typical instrumental activity of daily living was used as a trial scenario. As primary sensor modality, wearable inertial measurement units were employed. The results achievable by CSSM methods were evaluated by comparison with those obtained from established training-based methods (hidden Markov models, HMMs) using Wilcoxon signed rank tests. The influence of modeling factors on CSSM performance was analyzed via repeated measures analysis of variance. Results The symbolic domain model was found to have more than states, exceeding the complexity of models considered in previous research by at least three orders of magnitude. Nevertheless, if factors and procedures governing the inference process were suitably chosen, CSSMs outperformed HMMs. Specifically, inference methods used in previous studies (particle filters) were found to perform substantially inferior in comparison to a marginal filtering procedure. Conclusions Our results suggest that the combinatorial explosion caused by rich CSSM models does not inevitably lead to intractable inference or inferior performance. This means that the potential benefits of CSSM models (knowledge-based model construction, model reusability, reduced need for training data) are available without performance penalty. However, our results also show that research on CSSMs needs to consider sufficiently complex domains in order to understand the effects of design decisions such as choice of heuristics or inference procedure on performance.},
	language = {en},
	number = {11},
	urldate = {2022-07-26},
	journal = {PLOS ONE},
	author = {Krüger, Frank and Nyolt, Martin and Yordanova, Kristina and Hein, Albert and Kirste, Thomas},
	month = nov,
	year = {2014},
	note = {Publisher: Public Library of Science},
	keywords = {Random variables, Activities of daily living, Algorithms, Dynamical systems, Hidden Markov models, Language, Simulation and modeling, Statistical models, Symbolic Reasoning},
	pages = {e109381},
	file = {Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\INVVNB6D\\Krüger et al. - 2014 - Computational State Space Models for Activity and .pdf:application/pdf;Snapshot:C\:\\Users\\bened\\Zotero\\storage\\6F94EGX4\\article.html:text/html},
}

@inproceedings{papamakarios_masked_2017,
	title = {Masked {Autoregressive} {Flow} for {Density} {Estimation}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/6c1da886822c67822bcf3679d04369fa-Abstract.html},
	abstract = {Autoregressive models are among the best performing neural density estimators. We describe an approach for increasing the flexibility of an autoregressive model, based on modelling the random numbers that the model uses internally when generating data. By constructing a stack of autoregressive models, each modelling the random numbers of the next model in the stack, we obtain a type of normalizing flow suitable for density estimation, which we call Masked Autoregressive Flow. This type of flow is closely related to Inverse Autoregressive Flow and is a generalization of Real NVP. Masked Autoregressive Flow achieves state-of-the-art performance in a range of general-purpose density estimation tasks.},
	urldate = {2022-07-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Papamakarios, George and Pavlakou, Theo and Murray, Iain},
	year = {2017},
	file = {Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\7PJUIWRN\\Papamakarios et al. - 2017 - Masked Autoregressive Flow for Density Estimation.pdf:application/pdf},
}

@inproceedings{ramirez_goal_2011,
	title = {Goal {Recognition} over {POMDPs}: {Inferring} the {Intention} of a {POMDP} {Agent}},
	language = {en},
	booktitle = {Twenty-second international joint conference on artificial intelligence},
	author = {Ramirez, Miquel and Geffner, Hector},
	year = {2011},
	pages = {6},
	file = {Ramirez and Geffner - Goal Recognition over POMDPs Inferring the Intent.pdf:C\:\\Users\\bened\\Zotero\\storage\\8A6CY3CQ\\Ramirez and Geffner - Goal Recognition over POMDPs Inferring the Intent.pdf:application/pdf},
}

@article{moya_rueda_convolutional_2018,
	title = {Convolutional {Neural} {Networks} for {Human} {Activity} {Recognition} {Using} {Body}-{Worn} {Sensors}},
	volume = {5},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2227-9709},
	url = {https://www.mdpi.com/2227-9709/5/2/26},
	doi = {10.3390/informatics5020026},
	abstract = {Human activity recognition (HAR) is a classification task for recognizing human movements. Methods of HAR are of great interest as they have become tools for measuring occurrences and durations of human actions, which are the basis of smart assistive technologies and manual processes analysis. Recently, deep neural networks have been deployed for HAR in the context of activities of daily living using multichannel time-series. These time-series are acquired from body-worn devices, which are composed of different types of sensors. The deep architectures process these measurements for finding basic and complex features in human corporal movements, and for classifying them into a set of human actions. As the devices are worn at different parts of the human body, we propose a novel deep neural network for HAR. This network handles sequence measurements from different body-worn devices separately. An evaluation of the architecture is performed on three datasets, the Oportunity, Pamap2, and an industrial dataset, outperforming the state-of-the-art. In addition, different network configurations will also be evaluated. We find that applying convolutions per sensor channel and per body-worn device improves the capabilities of convolutional neural network (CNNs).},
	language = {en},
	number = {2},
	urldate = {2022-07-26},
	journal = {Informatics},
	author = {Moya Rueda, Fernando and Grzeszick, René and Fink, Gernot A. and Feldhorst, Sascha and Ten Hompel, Michael},
	month = jun,
	year = {2018},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {convolutional neural networks, human activity recognition, multichannel time-series, order picking},
	pages = {26},
	file = {Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\RLES67LH\\Moya Rueda et al. - 2018 - Convolutional Neural Networks for Human Activity R.pdf:application/pdf;Snapshot:C\:\\Users\\bened\\Zotero\\storage\\ES6DX6EU\\26.html:text/html},
}

@inproceedings{rueda_combining_2019,
	title = {Combining {Symbolic} {Reasoning} and {Deep} {Learning} for {Human} {Activity} {Recognition}},
	doi = {10.1109/PERCOMW.2019.8730792},
	booktitle = {2019 {IEEE} {International} {Conference} on {Pervasive} {Computing} and {Communications} {Workshops} ({PerCom} {Workshops})},
	author = {Rueda, Fernando Moya and Lüdtke, Stefan and Schröder, Max and Yordanova, Kristina and Kirste, Thomas and Fink, Gernot A.},
	month = mar,
	year = {2019},
	keywords = {Computational modeling, Context modeling, Activity recognition, Computer architecture, Deep learning, Feature extraction, Human Activity Recognition, Probabilistic logic, Symbolic Reasoning},
	pages = {22--27},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bened\\Zotero\\storage\\VYBWJPMG\\8730792.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\LZB55LBG\\Rueda et al. - 2019 - Combining Symbolic Reasoning and Deep Learning for.pdf:application/pdf},
}

@article{baker_action_2009,
	series = {Reinforcement learning and higher cognition},
	title = {Action understanding as inverse planning},
	volume = {113},
	issn = {0010-0277},
	url = {https://www.sciencedirect.com/science/article/pii/S0010027709001607},
	doi = {10.1016/j.cognition.2009.07.005},
	abstract = {Humans are adept at inferring the mental states underlying other agents’ actions, such as goals, beliefs, desires, emotions and other thoughts. We propose a computational framework based on Bayesian inverse planning for modeling human action understanding. The framework represents an intuitive theory of intentional agents’ behavior based on the principle of rationality: the expectation that agents will plan approximately rationally to achieve their goals, given their beliefs about the world. The mental states that caused an agent's behavior are inferred by inverting this model of rational planning using Bayesian inference, integrating the likelihood of the observed actions with the prior over mental states. This approach formalizes in precise probabilistic terms the essence of previous qualitative approaches to action understanding based on an “intentional stance” [Dennett, D. C. (1987). The intentional stance. Cambridge, MA: MIT Press] or a “teleological stance” [Gergely, G., Nádasdy, Z., Csibra, G., \& Biró, S. (1995). Taking the intentional stance at 12 months of age. Cognition, 56, 165–193]. In three psychophysical experiments using animated stimuli of agents moving in simple mazes, we assess how well different inverse planning models based on different goal priors can predict human goal inferences. The results provide quantitative evidence for an approximately rational inference mechanism in human goal inference within our simplified stimulus paradigm, and for the flexible nature of goal representations that human observers can adopt. We discuss the implications of our experimental results for human action understanding in real-world contexts, and suggest how our framework might be extended to capture other kinds of mental state inferences, such as inferences about beliefs, or inferring whether an entity is an intentional agent.},
	language = {en},
	number = {3},
	urldate = {2022-07-26},
	journal = {Cognition},
	author = {Baker, Chris L. and Saxe, Rebecca and Tenenbaum, Joshua B.},
	month = dec,
	year = {2009},
	keywords = {Action understanding, Bayesian models, Goal inference, Inverse reinforcement learning, Theory of mind},
	pages = {329--349},
	file = {ScienceDirect Snapshot:C\:\\Users\\bened\\Zotero\\storage\\AUHTHZIA\\S0010027709001607.html:text/html;Submitted Version:C\:\\Users\\bened\\Zotero\\storage\\UDB3ZMZL\\Baker et al. - 2009 - Action understanding as inverse planning.pdf:application/pdf},
}

@book{koller_probabilistic_2009,
	title = {Probabilistic {Graphical} {Models}: {Principles} and {Techniques}},
	isbn = {978-0-262-01319-2},
	shorttitle = {Probabilistic {Graphical} {Models}},
	abstract = {A general framework for constructing and using probabilistic models of complex systems that would enable a computer to use available information for making decisions.Most tasks require a person or an automated system to reason—to reach conclusions based on available information. The framework of probabilistic graphical models, presented in this book, provides a general approach for this task. The approach is model-based, allowing interpretable models to be constructed and then manipulated by reasoning algorithms. These models can also be learned automatically from data, allowing the approach to be used in cases where manually constructing a model is difficult or even impossible. Because uncertainty is an inescapable aspect of most real-world applications, the book focuses on probabilistic models, which make the uncertainty explicit and provide models that are more faithful to reality. Probabilistic Graphical Models discusses a variety of models, spanning Bayesian networks, undirected Markov networks, discrete and continuous models, and extensions to deal with dynamical systems and relational data. For each class of models, the text describes the three fundamental cornerstones: representation, inference, and learning, presenting both basic concepts and advanced techniques. Finally, the book considers the use of the proposed framework for causal reasoning and decision making under uncertainty. The main text in each chapter provides the detailed technical development of the key ideas. Most chapters also include boxes with additional material: skill boxes, which describe techniques; case study boxes, which discuss empirical cases related to the approach described in the text, including applications in computer vision, robotics, natural language understanding, and computational biology; and concept boxes, which present significant concepts drawn from the material in the chapter. Instructors (and readers) can group chapters in various combinations, from core topics to more technically advanced material, to suit their particular needs.},
	language = {en},
	publisher = {MIT Press},
	author = {Koller, Daphne and Friedman, Nir},
	month = jul,
	year = {2009},
	note = {Google-Books-ID: 7dzpHCHzNQ4C},
	keywords = {Computers / Artificial Intelligence / General},
}

@article{chen_sensor-based_2012,
	title = {Sensor-{Based} {Activity} {Recognition}},
	volume = {42},
	issn = {1558-2442},
	doi = {10.1109/TSMCC.2012.2198883},
	abstract = {Research on sensor-based activity recognition has, recently, made significant progress and is attracting growing attention in a number of disciplines and application domains. However, there is a lack of high-level overview on this topic that can inform related communities of the research state of the art. In this paper, we present a comprehensive survey to examine the development and current status of various aspects of sensor-based activity recognition. We first discuss the general rationale and distinctions of vision-based and sensor-based activity recognition. Then, we review the major approaches and methods associated with sensor-based activity monitoring, modeling, and recognition from which strengths and weaknesses of those approaches are highlighted. We make a primary distinction in this paper between data-driven and knowledge-driven approaches, and use this distinction to structure our survey. We also discuss some promising directions for future research.},
	number = {6},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {Chen, Liming and Hoey, Jesse and Nugent, Chris D. and Cook, Diane J. and Yu, Zhiwen},
	month = nov,
	year = {2012},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	keywords = {Data models, Hidden Markov models, Activity modeling, activity monitoring, activity recognition, Biomedical monitoring, dense sensing, Human factors, Monitoring, pervasive computing, Wearable sensors},
	pages = {790--808},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bened\\Zotero\\storage\\CDFEFCKX\\6208895.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\I4YA9HJL\\Chen et al. - 2012 - Sensor-Based Activity Recognition.pdf:application/pdf},
}

@misc{manhaeve_neural_2019,
	title = {Neural {Probabilistic} {Logic} {Programming} in {DeepProbLog}},
	url = {http://arxiv.org/abs/1907.08194},
	abstract = {We introduce DeepProbLog, a neural probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques of the underlying probabilistic logic programming language ProbLog can be adapted for the new language. We theoretically and experimentally demonstrate that DeepProbLog supports (i) both symbolic and subsymbolic representations and inference, (ii) program induction, (iii) probabilistic (logic) programming, and (iv) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples.},
	urldate = {2022-09-06},
	publisher = {arXiv},
	author = {Manhaeve, Robin and Dumančić, Sebastijan and Kimmig, Angelika and Demeester, Thomas and De Raedt, Luc},
	month = sep,
	year = {2019},
	note = {arXiv:1907.08194 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\H8WR9FPF\\Manhaeve et al. - 2019 - Neural Probabilistic Logic Programming in DeepProb.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\3VWEQSII\\1907.html:text/html},
}

@inproceedings{manhaeve_deepproblog_2018,
	title = {{DeepProbLog}: {Neural} {Probabilistic} {Logic} {Programming}},
	volume = {31},
	shorttitle = {{DeepProbLog}},
	url = {https://proceedings.neurips.cc/paper/2018/hash/dc5d637ed5e62c36ecb73b654b05ba2a-Abstract.html},
	abstract = {We introduce DeepProbLog, a probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques can be adapted for the new language. Our experiments demonstrate that DeepProbLog supports (i) both symbolic and subsymbolic representations and inference, (ii) program induction, (iii) probabilistic (logic) programming, and (iv) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples.},
	urldate = {2022-09-06},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Manhaeve, Robin and Dumancic, Sebastijan and Kimmig, Angelika and Demeester, Thomas and De Raedt, Luc},
	year = {2018},
	keywords = {Hybrid},
	file = {Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\IJJH8KTW\\Manhaeve et al. - 2018 - DeepProbLog Neural Probabilistic Logic Programmin.pdf:application/pdf},
}

@misc{hammerla_deep_2016,
	title = {Deep, {Convolutional}, and {Recurrent} {Models} for {Human} {Activity} {Recognition} using {Wearables}},
	url = {http://arxiv.org/abs/1604.08880},
	abstract = {Human activity recognition (HAR) in ubiquitous computing is beginning to adopt deep learning to substitute for well-established analysis techniques that rely on hand-crafted feature extraction and classification techniques. From these isolated applications of custom deep architectures it is, however, difficult to gain an overview of their suitability for problems ranging from the recognition of manipulative gestures to the segmentation and identification of physical activities like running or ascending stairs. In this paper we rigorously explore deep, convolutional, and recurrent approaches across three representative datasets that contain movement data captured with wearable sensors. We describe how to train recurrent approaches in this setting, introduce a novel regularisation approach, and illustrate how they outperform the state-of-the-art on a large benchmark dataset. Across thousands of recognition experiments with randomly sampled model configurations we investigate the suitability of each model for different tasks in HAR, explore the impact of hyperparameters using the fANOVA framework, and provide guidelines for the practitioner who wants to apply deep learning in their problem setting.},
	urldate = {2022-09-06},
	publisher = {arXiv},
	author = {Hammerla, Nils Y. and Halloran, Shane and Ploetz, Thomas},
	month = apr,
	year = {2016},
	note = {arXiv:1604.08880 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Human-Computer Interaction},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\RLIUPZKK\\Hammerla et al. - 2016 - Deep, Convolutional, and Recurrent Models for Huma.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\VXLG3B2U\\1604.html:text/html},
}

@inproceedings{riboni_unsupervised_2016,
	address = {Heidelberg Germany},
	title = {Unsupervised recognition of interleaved activities of daily living through ontological and probabilistic reasoning},
	isbn = {978-1-4503-4461-6},
	url = {https://dl.acm.org/doi/10.1145/2971648.2971691},
	doi = {10.1145/2971648.2971691},
	abstract = {Recognition of activities of daily living (ADLs) is an enabling technology for several ubiquitous computing applications. In this ﬁeld, most activity recognition systems rely on supervised learning methods to extract activity models from labeled datasets. An inherent problem of that approach consists in the acquisition of comprehensive activity datasets, which is expensive and may violate individuals’ privacy. The problem is particularly challenging when focusing on complex ADLs, which are characterized by large intra- and inter-personal variability of execution. In this paper, we propose an unsupervised method to recognize complex ADLs exploiting the semantics of activities, context data, and sensing devices. Through ontological reasoning, we derive semantic correlations among activities and sensor events. By matching observed sensor events with semantic correlations, a statistical reasoner formulates initial hypotheses about the occurred activities. Those hypotheses are reﬁned through probabilistic reasoning, exploiting semantic constraints derived from the ontology. Extensive experiments with real-world datasets show that the accuracy of our unsupervised method is comparable to the one of state of the art supervised approaches.},
	language = {en},
	urldate = {2022-09-06},
	booktitle = {Proceedings of the 2016 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Riboni, Daniele and Sztyler, Timo and Civitarese, Gabriele and Stuckenschmidt, Heiner},
	month = sep,
	year = {2016},
	keywords = {Symbolic Reasoning},
	pages = {1--12},
}

@article{ordonez_deep_2016,
	title = {Deep {Convolutional} and {LSTM} {Recurrent} {Neural} {Networks} for {Multimodal} {Wearable} {Activity} {Recognition}},
	volume = {16},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/16/1/115},
	doi = {10.3390/s16010115},
	abstract = {Human activity recognition (HAR) tasks have traditionally been solved using engineered features obtained by heuristic processes. Current research suggests that deep convolutional neural networks are suited to automate feature extraction from raw sensor inputs. However, human activities are made of complex sequences of motor movements, and capturing this temporal dynamics is fundamental for successful HAR. Based on the recent success of recurrent neural networks for time series domains, we propose a generic deep framework for activity recognition based on convolutional and LSTM recurrent units, which: (i) is suitable for multimodal wearable sensors; (ii) can perform sensor fusion naturally; (iii) does not require expert knowledge in designing features; and (iv) explicitly models the temporal dynamics of feature activations. We evaluate our framework on two datasets, one of which has been used in a public activity recognition challenge. Our results show that our framework outperforms competing deep non-recurrent networks on the challenge dataset by 4\% on average; outperforming some of the previous reported results by up to 9\%. Our results show that the framework can be applied to homogeneous sensor modalities, but can also fuse multimodal sensors to improve performance. We characterise key architectural hyperparameters’ influence on performance to provide insights about their optimisation.},
	language = {en},
	number = {1},
	urldate = {2022-09-06},
	journal = {Sensors},
	author = {Ordóñez, Francisco Javier and Roggen, Daniel},
	month = jan,
	year = {2016},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {deep learning, machine learning, human activity recognition, LSTM, neural network, sensor fusion, wearable sensors, Neural},
	pages = {115},
	file = {Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\UQHQU4LN\\Ordóñez and Roggen - 2016 - Deep Convolutional and LSTM Recurrent Neural Netwo.pdf:application/pdf;Snapshot:C\:\\Users\\bened\\Zotero\\storage\\6W26NBKL\\html.html:text/html},
}

@misc{yao_efficient_2017,
	title = {Efficient {Dense} {Labeling} of {Human} {Activity} {Sequences} from {Wearables} using {Fully} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1702.06212},
	abstract = {Recognizing human activities in a sequence is a challenging area of research in ubiquitous computing. Most approaches use a fixed size sliding window over consecutive samples to extract features---either handcrafted or learned features---and predict a single label for all samples in the window. Two key problems emanate from this approach: i) the samples in one window may not always share the same label. Consequently, using one label for all samples within a window inevitably lead to loss of information; ii) the testing phase is constrained by the window size selected during training while the best window size is difficult to tune in practice. We propose an efficient algorithm that can predict the label of each sample, which we call dense labeling, in a sequence of human activities of arbitrary length using a fully convolutional network. In particular, our approach overcomes the problems posed by the sliding window step. Additionally, our algorithm learns both the features and classifier automatically. We release a new daily activity dataset based on a wearable sensor with hospitalized patients. We conduct extensive experiments and demonstrate that our proposed approach is able to outperform the state-of-the-arts in terms of classification and label misalignment measures on three challenging datasets: Opportunity, Hand Gesture, and our new dataset.},
	urldate = {2022-09-06},
	publisher = {arXiv},
	author = {Yao, Rui and Lin, Guosheng and Shi, Qinfeng and Ranasinghe, Damith},
	month = feb,
	year = {2017},
	note = {arXiv:1702.06212 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Human-Computer Interaction, neural network},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\GYMBRTHH\\Yao et al. - 2017 - Efficient Dense Labeling of Human Activity Sequenc.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\E7P5UG2P\\1702.html:text/html},
}

@article{chen_deep_2022,
	title = {Deep {Learning} for {Sensor}-based {Human} {Activity} {Recognition}: {Overview}, {Challenges}, and {Opportunities}},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Deep {Learning} for {Sensor}-based {Human} {Activity} {Recognition}},
	url = {https://dl.acm.org/doi/10.1145/3447744},
	doi = {10.1145/3447744},
	abstract = {The vast proliferation of sensor devices and Internet of Things enables the applications of sensor-based activity recognition. However, there exist substantial challenges that could influence the performance of the recognition system in practical scenarios. Recently, as deep learning has demonstrated its effectiveness in many areas, plenty of deep methods have been investigated to address the challenges in activity recognition. In this study, we present a survey of the state-of-the-art deep learning methods for sensor-based human activity recognition. We first introduce the multi-modality of the sensory data and provide information for public datasets that can be used for evaluation in different challenge tasks. We then propose a new taxonomy to structure the deep methods by challenges. Challenges and challenge-related deep methods are summarized and analyzed to form an overview of the current research progress. At the end of this work, we discuss the open issues and provide some insights for future directions.},
	language = {en},
	number = {4},
	urldate = {2022-09-06},
	journal = {ACM Computing Surveys},
	author = {Chen, Kaixuan and Zhang, Dalin and Yao, Lina and Guo, Bin and Yu, Zhiwen and Liu, Yunhao},
	month = may,
	year = {2022},
	keywords = {Deep Neural Network, neural network},
	pages = {1--40},
	file = {Chen et al. - 2022 - Deep Learning for Sensor-based Human Activity Reco.pdf:C\:\\Users\\bened\\Zotero\\storage\\GJMREEQM\\Chen et al. - 2022 - Deep Learning for Sensor-based Human Activity Reco.pdf:application/pdf},
}

@article{shavit_boosting_2021,
	title = {Boosting {Inertial}-{Based} {Human} {Activity} {Recognition} {With} {Transformers}},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3070646},
	journal = {IEEE Access},
	author = {Shavit, Yoli and Klein, Itzik},
	year = {2021},
	keywords = {Neural networks, convolutional neural networks, Activity recognition, Accelerometers, Belts, Human activity recognition, inertial sensors, Legged locomotion, Magnetic heads, pedestrian dead reckoning, sequence analysis, smartphone location recognition, Stairs, Task analysis, Transformers},
	pages = {53540--53547},
}

@inproceedings{sztyler_modeling_2018,
	title = {Modeling and {Reasoning} with {ProbLog}: {An} {Application} in {Recognizing} {Complex} {Activities}},
	shorttitle = {Modeling and {Reasoning} with {ProbLog}},
	doi = {10.1109/PERCOMW.2018.8480299},
	abstract = {Smart-home activity recognition is an enabling tool for a wide range of ambient assisted living applications. The recognition of ADLs usually relies on supervised learning or knowledge-based reasoning techniques. In order to overcome the well-known limitations of those two approaches and, at the same time, to combine their strengths to improve the recognition rate, many researchers investigated Markov Logic Networks (MLNs). However, MLNs require a non-trivial effort by experts to properly model probabilities in terms of weights. In this paper, we propose a novel method based on ProbLog. ProbLog is a probabilistic extension of Prolog, which allows to explicitly define probabilistic facts and rules. With respect to MLN, the inference mode of ProbLog is based on the closed-world assumption and it has faster response times. We propose a simple and flexible ProbLog model, which we exploit to recognize complex ADLs in an online fashion. Considering a dataset with 21 subjects, our results show that our method reaches high F-measure (83\%). Moreover, we also show that the response time of ProbLog is satisfying for real-time applications.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Pervasive} {Computing} and {Communications} {Workshops} ({PerCom} {Workshops})},
	author = {Sztyler, Timo and Civitarese, Gabriele and Stuckenschmidt, Heiner},
	month = mar,
	year = {2018},
	keywords = {Context modeling, Random variables, Activity recognition, Probabilistic logic, Symbolic Reasoning, Knowledge based systems, Sensor phenomena and characterization},
	pages = {259--264},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bened\\Zotero\\storage\\852NSZ5E\\8480299.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\CET8DBJW\\Sztyler et al. - 2018 - Modeling and Reasoning with ProbLog An Applicatio.pdf:application/pdf},
}

@misc{ludtke_lifted_2018,
	title = {Lifted {Filtering} via {Exchangeable} {Decomposition}},
	url = {http://arxiv.org/abs/1801.10495},
	urldate = {2022-09-06},
	publisher = {arXiv},
	author = {Lüdtke, Stefan and Schröder, Max and Bader, Sebastian and Kersting, Kristian and Kirste, Thomas},
	month = may,
	year = {2018},
	note = {arXiv:1801.10495 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Symbolic Reasoning},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\XQ8NKNFL\\Lüdtke et al. - 2018 - Lifted Filtering via Exchangeable Decomposition.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\PYTQX7GM\\1801.html:text/html},
}

@article{civitarese_polaris_2021,
	title = {{POLARIS}: {Probabilistic} and {Ontological} {Activity} {Recognition} in {Smart}-{Homes}},
	volume = {33},
	issn = {1558-2191},
	shorttitle = {{POLARIS}},
	doi = {10.1109/TKDE.2019.2930050},
	number = {1},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Civitarese, Gabriele and Sztyler, Timo and Riboni, Daniele and Bettini, Claudio and Stuckenschmidt, Heiner},
	month = jan,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	keywords = {Ontologies, Activity recognition, Probabilistic logic, Symbolic Reasoning, pervasive computing, Correlation, online/offline activity recognition, Ontological reasoning, probabilistic reasoning, Semantics, unsupervised classification},
	pages = {209--223},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bened\\Zotero\\storage\\4MPH7G8B\\8769915.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\8TDT3IQR\\Civitarese et al. - 2021 - POLARIS Probabilistic and Ontological Activity Re.pdf:application/pdf},
}

@misc{garcez_neurosymbolic_2020,
	title = {Neurosymbolic {AI}: {The} 3rd {Wave}},
	shorttitle = {Neurosymbolic {AI}},
	url = {http://arxiv.org/abs/2012.05876},
	urldate = {2022-09-06},
	publisher = {arXiv},
	author = {Garcez, Artur d'Avila and Lamb, Luis C.},
	month = dec,
	year = {2020},
	note = {arXiv:2012.05876 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Neuro-symbolic, Hybrid, Overview},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\A5H744GJ\\Garcez and Lamb - 2020 - Neurosymbolic AI The 3rd Wave.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\9SBA23SG\\2012.html:text/html},
}

@misc{ludtke_human_2021,
	title = {Human {Activity} {Recognition} using {Attribute}-{Based} {Neural} {Networks} and {Context} {Information}},
	url = {http://arxiv.org/abs/2111.04564},
	urldate = {2022-09-06},
	publisher = {arXiv},
	author = {Lüdtke, Stefan and Rueda, Fernando Moya and Ahmed, Waqas and Fink, Gernot A. and Kirste, Thomas},
	month = oct,
	year = {2021},
	note = {arXiv:2111.04564 [cs, eess]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\93HXTXAW\\Lüdtke et al. - 2021 - Human Activity Recognition using Attribute-Based N.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\TUKE27GG\\2111.html:text/html},
}

@article{germain_made_nodate,
	title = {{MADE}: {Masked} {Autoencoder} for {Distribution} {Estimation}},
	doi = {10.48550/ARXIV.1502.03509},
	url = {https://arxiv.org/abs/1502.03509},
	language = {en},
	author = {Germain, Mathieu and Gregor, Karol and Murray, Iain and Larochelle, Hugo},
	publisher = {arXiv},
	year = {2015},
	pages = {9},
	file = {Germain et al. - MADE Masked Autoencoder for Distribution Estimati.pdf:C\:\\Users\\bened\\Zotero\\storage\\FC2KU8HM\\Germain et al. - MADE Masked Autoencoder for Distribution Estimati.pdf:application/pdf},
}

@inproceedings{schmah_generative_2008,
	title = {Generative versus discriminative training of {RBMs} for classification of {fMRI} images},
	volume = {21},
	url = {https://proceedings.neurips.cc/paper/2008/hash/3e77a14629775492504515dc4b23deda-Abstract.html},
	urldate = {2022-09-07},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Schmah, Tanya and Hinton, Geoffrey E and Small, Steven and Strother, Stephen and Zemel, Richard},
	year = {2008},
	keywords = {Background},
	file = {Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\XTDLAECF\\Schmah et al. - 2008 - Generative versus discriminative training of RBMs .pdf:application/pdf},
}

@article{raedt_problog_nodate,
	title = {{ProbLog}: {A} {Probabilistic} {Prolog} and {Its} {Application} in {Link} {Discovery}},
	language = {en},
	author = {Raedt, Luc De},
	pages = {6},
	file = {Raedt - ProbLog A Probabilistic Prolog and Its Applicatio.pdf:C\:\\Users\\bened\\Zotero\\storage\\G5ANZRXE\\Raedt - ProbLog A Probabilistic Prolog and Its Applicatio.pdf:application/pdf},
}

@inproceedings{arrotta_knowledge_2022,
	title = {Knowledge {Infusion} for {Context}-{Aware} {Sensor}-{Based} {Human} {Activity} {Recognition}},
	doi = {10.1109/SMARTCOMP55677.2022.00016},
	booktitle = {2022 {IEEE} {International} {Conference} on {Smart} {Computing} ({SMARTCOMP})},
	author = {Arrotta, Luca and Civitarese, Gabriele and Bettini, Claudio},
	month = jun,
	year = {2022},
	note = {ISSN: 2693-8340},
	keywords = {Data models, neuro-symbolic AI, Training, Neural networks, Ontologies, Deep learning, Feature extraction, activity recognition, Knowledge engineering, knowledge infusion, hybrid},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bened\\Zotero\\storage\\BXLFZRTH\\9821036.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\LFCA75HV\\Arrotta et al. - 2022 - Knowledge Infusion for Context-Aware Sensor-Based .pdf:application/pdf},
}

@article{sukor_hybrid_2019,
	title = {A hybrid approach of knowledge-driven and data-driven reasoning for activity recognition in smart homes},
	volume = {36},
	issn = {10641246, 18758967},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/JIFS-169976},
	doi = {10.3233/JIFS-169976},
	language = {en},
	number = {5},
	urldate = {2022-11-24},
	journal = {Journal of Intelligent \& Fuzzy Systems},
	author = {Sukor, Abdul Syafiq Abdull and Zakaria, Ammar and Rahim, Norasmadi Abdul and Kamarudin, Latifah Munirah and Setchi, Rossi and Nishizaki, Hiromitsu},
	editor = {Vijayakumar, V. and Subramaniyaswamy, V. and Abawajy, Jemal and Yang, Longzhi},
	month = may,
	year = {2019},
	pages = {4177--4188},
	file = {Sukor et al. - 2019 - A hybrid approach of knowledge-driven and data-dri.pdf:C\:\\Users\\bened\\Zotero\\storage\\ME2Y5CTS\\Sukor et al. - 2019 - A hybrid approach of knowledge-driven and data-dri.pdf:application/pdf},
}

@article{bettini_caviar_2020,
	title = {{CAVIAR}: {Context}-driven {Active} and {Incremental} {Activity} {Recognition}},
	volume = {196},
	issn = {09507051},
	shorttitle = {{CAVIAR}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705120301969},
	doi = {10.1016/j.knosys.2020.105816},
	language = {en},
	urldate = {2022-11-24},
	journal = {Knowledge-Based Systems},
	author = {Bettini, Claudio and Civitarese, Gabriele and Presotto, Riccardo},
	month = may,
	year = {2020},
	pages = {105816},
	file = {Bettini et al. - 2020 - CAVIAR Context-driven Active and Incremental Acti.pdf:C\:\\Users\\bened\\Zotero\\storage\\V5XAJMXQ\\Bettini et al. - 2020 - CAVIAR Context-driven Active and Incremental Acti.pdf:application/pdf},
}


@misc{kostrikov_pytorch-flows_2022,
	title = {pytorch-flows},
	copyright = {MIT},
	howpublished = "\url{https://github.com/ikostrikov/pytorch-flows}",
	abstract = {PyTorch implementations of algorithms for density estimation},
	author = {Kostrikov, Ilya},
	month = sep,
	year = {2018},
	note = {Online; accessed 2022-10-14},
	keywords = {deep-learning, density-estimation, neural-networks, probabilities, pytorch},
}

@misc{um_augmentation_2017,
	title = {Python implementation of Data Augmentation For Wearable Sensor Data},
	howpublished = "\url{https://github.com/terryum/Data-Augmentation-For-Wearable-Sensor-Data}",
	author = {Um, Terry Taewoong},
	month = aug,
	year = {2017},
	note = {Online; accessed 2022-12-01},
}

@inproceedings{anguita_public_2013,
	address = {Bruges, Belgium},
	title = {A {Public} {Domain} {Dataset} for {Human} {Activity} {Recognition} {Using} {Smartphones}},
	booktitle = {21th {European} {Symposium} on {Artificial} {Neural} {Networks}, {Computational} {Intelligence} and {Machine} {Learning}},
	author = {Anguita, Davide and Ghio, Alessandro and Oneto, Luca and Parra, Xavier and Reyes-Ortiz, Jorge L.},
	month = apr,
	year = {2013},
	howpublished = "\url{https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones}",
}

@inproceedings{malekzadeh_mobile_2019,
	address = {Montreal, Quebec, Canada},
	title = {Mobile {Sensor} {Data} {Anonymization}},
	isbn = {978-1-4503-6283-2},
	url = {http://doi.acm.org/10.1145/3302505.3310068},
	doi = {10.1145/3302505.3310068},
	booktitle = {Proceedings of the {International} {Conference} on {Internet} of {Things} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Malekzadeh, Mohammad and Clegg, Richard G. and Cavallaro, Andrea and Haddadi, Hamed},
	year = {2019},
	pages = {49--58},
	howpublished = "\url{https://github.com/mmalekzadeh/motion-sense/tree/master/data}"
}

@misc{kruger_recognising_2011,
	title = {Recognising user actions during cooking task ({Cooking} task dataset): {IMU} {Data}},
	copyright = {CC BY 4.0},
	shorttitle = {Recognising user actions during cooking task ({Cooking} task dataset)},
	howpublished = "\url{https://rosdok.uni-rostock.de/resolve/id/rosdok_document_0000010639}",
	urldate = {2023-01-03},
	author = {Krüger, Frank and Hein, Albert and Yordanova, Kristina and Kirste, Thomas},
	year = {2011},
	note = {Publisher: University of Rostock},
	file = {Snapshot:C\:\\Users\\bened\\Zotero\\storage\\MJ8EQNNB\\rosdok_document_0000010639.html:text/html},
}

@inproceedings{um_data_2017,
	title = {Data {Augmentation} of {Wearable} {Sensor} {Data} for {Parkinson}'s {Disease} {Monitoring} using {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1706.00527},
	doi = {10.1145/3136755.3136817},
	urldate = {2023-01-03},
	booktitle = {Proceedings of the 19th {ACM} {International} {Conference} on {Multimodal} {Interaction}},
	author = {Um, Terry Taewoong and Pfister, Franz Michael Josef and Pichler, Daniel and Endo, Satoshi and Lang, Muriel and Hirche, Sandra and Fietzek, Urban and Kulić, Dana},
	month = nov,
	year = {2017},
	note = {arXiv:1706.00527 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {216--220},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\F52QKR9I\\Um et al. - 2017 - Data Augmentation of Wearable Sensor Data for Park.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\2ZZ3AQ3U\\1706.html:text/html},
}


@inproceedings{eldele_time-series_2021,
	address = {Montreal, Canada},
	title = {Time-{Series} {Representation} {Learning} via {Temporal} and {Contextual} {Contrasting}},
	isbn = {978-0-9992411-9-6},
	url = {https://www.ijcai.org/proceedings/2021/324},
	doi = {10.24963/ijcai.2021/324},
	abstract = {Learning decent representations from unlabeled time-series data with temporal dynamics is a very challenging task. In this paper, we propose an unsupervised Time-Series representation learning framework via Temporal and Contextual Contrasting (TS-TCC), to learn time-series representation from unlabeled data. First, the raw timeseries data are transformed into two different yet correlated views by using weak and strong augmentations. Second, we propose a novel temporal contrasting module to learn robust temporal representations by designing a tough cross-view prediction task. Last, to further learn discriminative representations, we propose a contextual contrasting module built upon the contexts from the temporal contrasting module. It attempts to maximize the similarity among different contexts of the same sample while minimizing similarity among contexts of different samples. Experiments have been carried out on three real-world time-series datasets. The results manifest that training a linear classiﬁer on top of the features learned by our proposed TS-TCC performs comparably with the supervised training. Additionally, our proposed TS-TCC shows high efﬁciency in few-labeled data and transfer learning scenarios. The code is publicly available at https://github.com/emadeldeen24/TS-TCC.},
	language = {en},
	urldate = {2023-01-04},
	booktitle = {Proceedings of the {Thirtieth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Eldele, Emadeldeen and Ragab, Mohamed and Chen, Zhenghua and Wu, Min and Kwoh, Chee Keong and Li, Xiaoli and Guan, Cuntai},
	month = aug,
	year = {2021},
	pages = {2352--2359},
	file = {Eldele et al. - 2021 - Time-Series Representation Learning via Temporal a.pdf:C\:\\Users\\bened\\Zotero\\storage\\D235HWHX\\Eldele et al. - 2021 - Time-Series Representation Learning via Temporal a.pdf:application/pdf},
}

@misc{dinh_density_2017,
	title = {Density estimation using {Real} {NVP}},
	url = {http://arxiv.org/abs/1605.08803},
	doi = {10.48550/arXiv.1605.08803},
	abstract = {Unsupervised learning of probabilistic models is a central yet challenging problem in machine learning. Specifically, designing models with tractable learning, sampling, inference and evaluation is crucial in solving this task. We extend the space of such models using real-valued non-volume preserving (real NVP) transformations, a set of powerful invertible and learnable transformations, resulting in an unsupervised learning algorithm with exact log-likelihood computation, exact sampling, exact inference of latent variables, and an interpretable latent space. We demonstrate its ability to model natural images on four datasets through sampling, log-likelihood evaluation and latent variable manipulations.},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
	month = feb,
	year = {2017},
	note = {arXiv:1605.08803 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\9QCJGF8A\\Dinh et al. - 2017 - Density estimation using Real NVP.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\2GGAF7BE\\1605.html:text/html},
}

@misc{kingma_glow_2018,
	title = {Glow: {Generative} {Flow} with {Invertible} 1x1 {Convolutions}},
	shorttitle = {Glow},
	url = {http://arxiv.org/abs/1807.03039},
	doi = {10.48550/arXiv.1807.03039},
	abstract = {Flow-based generative models (Dinh et al., 2014) are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using an invertible 1x1 convolution. Using our method we demonstrate a significant improvement in log-likelihood on standard benchmarks. Perhaps most strikingly, we demonstrate that a generative model optimized towards the plain log-likelihood objective is capable of efficient realistic-looking synthesis and manipulation of large images. The code for our model is available at https://github.com/openai/glow},
	urldate = {2023-01-04},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Dhariwal, Prafulla},
	month = jul,
	year = {2018},
	note = {arXiv:1807.03039 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\bened\\Zotero\\storage\\K92LQSEX\\Kingma and Dhariwal - 2018 - Glow Generative Flow with Invertible 1x1 Convolut.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\bened\\Zotero\\storage\\FS2BKF8X\\1807.html:text/html},
}

@article{nyolt_marginal_2015,
	title = {Marginal filtering in large state spaces},
	volume = {61},
	issn = {0888-613X},
	url = {https://www.sciencedirect.com/science/article/pii/S0888613X15000511},
	doi = {10.1016/j.ijar.2015.04.003},
	abstract = {Recognising everyday activities including information about the context requires to handle large state spaces. The usage of wearable sensors like six degree of freedom accelerometers increases complexity even more. Common approaches are unable to maintain an accurate belief state within such complex domains. We show how marginal filtering can overcome limitations of standard particle filtering and efficiently infer the context of actions. Symbolic models of human behaviour are used to recognise activities in two different settings with different state space sizes. Based on these scenarios we compare the marginal filter to the standard particle filter. An evaluation shows that the marginal filter performs comparably in small state spaces but outperforms the particle filter in large state spaces.},
	language = {en},
	urldate = {2023-01-07},
	journal = {International Journal of Approximate Reasoning},
	author = {Nyolt, Martin and Krüger, Frank and Yordanova, Kristina and Hein, Albert and Kirste, Thomas},
	month = jun,
	year = {2015},
	keywords = {Activity recognition, Bayesian inference, Marginal filter, Particle filter, Plan recognition, Symbolic models},
	pages = {16--32},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\8LBW3TNI\\Nyolt et al. - 2015 - Marginal filtering in large state spaces.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\bened\\Zotero\\storage\\CPE8DUAG\\S0888613X15000511.html:text/html},
}


@article{ronald_isplinception_2021,
	title = {{iSPLInception}: {An} {Inception}-{ResNet} {Deep} {Learning} {Architecture} for {Human} {Activity} {Recognition}},
	volume = {9},
	issn = {2169-3536},
	shorttitle = {{iSPLInception}},
	doi = {10.1109/ACCESS.2021.3078184},
	journal = {IEEE Access},
	author = {Ronald, Mutegeki and Poulose, Alwin and Han, Dong Seog},
	year = {2021},
	note = {Conference Name: IEEE Access},
	keywords = {Activity recognition, Computer architecture, deep learning, Deep learning, Human activity recognition, inception module, Inception-ResNet, Monitoring, Service-oriented architecture, Smart phones, Task analysis, time-series classification},
	pages = {68985--69001},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bened\\Zotero\\storage\\5XT4G5F2\\9425494.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\bened\\Zotero\\storage\\5Y8LTUTC\\Ronald et al. - 2021 - iSPLInception An Inception-ResNet Deep Learning A.pdf:application/pdf},
}
